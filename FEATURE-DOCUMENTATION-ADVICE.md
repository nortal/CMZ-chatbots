# Feature Documentation Agent - Best Practices and Implementation Guide

## Purpose
This guide provides best practices, patterns, and troubleshooting advice for the Feature Documentation Agent that generates hierarchical feature documentation from requirements, code, and specifications.

## Core Principles

### 1. Documentation Hierarchy
Always follow the hierarchical structure:
```
System ‚Üí Feature ‚Üí Component ‚Üí Field ‚Üí Test
```

Each level serves a specific purpose:
- **System**: Overall platform capabilities and architecture
- **Feature**: Business value and user capabilities
- **Component**: UI dialogs, pages, API endpoints
- **Field**: Individual inputs, controls, buttons with detailed specifications
- **Test**: Expected behavior, edge cases, validation rules

### 2. User-Centric Language
- **High-level docs** (Feature, Component): Use business language for non-technical stakeholders
- **Field-level docs**: Balance technical accuracy with user understanding
- **Test docs**: Use precise technical language for QA engineers

**Example**:
```markdown
<!-- Feature Level (Business Language) -->
Family Management allows zookeepers and admins to organize students into family
groups, enabling parents to review and edit conversations by students in their family.

<!-- Field Level (Balanced) -->
System Prompt: This field contains the English language prompt provided alongside
a chat message from a user. It should contain active guardrails and the personality
of the response that can be auto-generated by the system on demand, then edited by
the zookeeper.

<!-- Test Level (Technical) -->
System Prompt Validation: maxLength=2000, minLength=10, pattern=/^[a-zA-Z0-9\s,.!?-]+$/,
required=true. Edge cases: empty string (reject), 2001 chars (reject), special chars (reject).
```

### 3. Single Source of Truth
- OpenAPI specification is authoritative for validation rules
- Frontend code is authoritative for UI behavior
- Requirements documents are authoritative for business value
- When sources conflict, document the conflict and ask user for clarification

## Phase-by-Phase Implementation Guide

### Phase 1: Source Discovery and Analysis

**Best Practices**:
1. **Start with CLAUDE.md** - Contains architecture overview and project context
2. **Read OpenAPI spec first** - Understand the complete API surface
3. **Map frontend routes** - Identify all user-facing pages and dialogs
4. **Track source files** - Maintain list of all files examined for update detection

**Common Issues**:
- **Missing requirements**: If no PRD exists, use OpenAPI spec + component analysis
- **Outdated docs**: Check git blame to find when docs were last updated
- **Conflicting information**: Document conflicts in Phase 5 questions

**Pattern - Source File Tracking**:
```markdown
# sources/code-analyzed.md

## Frontend Sources (Last Updated: 2025-10-12)
- frontend/src/components/AnimalConfigDialog.tsx (analyzed)
- frontend/src/components/FamilyDialog.tsx (analyzed)
- frontend/src/pages/Dashboard.tsx (analyzed)

## Backend Sources (Last Updated: 2025-10-12)
- backend/api/openapi_spec.yaml (analyzed)
- backend/api/src/main/python/openapi_server/impl/animals.py (analyzed)
- backend/api/src/main/python/openapi_server/impl/family.py (analyzed)

## Requirements Sources (Last Updated: 2025-10-12)
- CLAUDE.md (Architecture Overview section)
- Jira PR003946-* tickets (20 tickets analyzed)
- No formal PRD documents found
```

### Phase 2: Feature Identification and Hierarchy

**Best Practices**:
1. **Group by business capability** - Not by technical implementation
2. **Use user-facing names** - "Animal Configuration" not "animal_config_patch endpoint"
3. **Identify cross-cutting features** - Auth, logging, error handling affect all features

**Feature Identification Pattern**:
```markdown
# Feature Identification Checklist

## OpenAPI Endpoint Groups
- /auth/* ‚Üí Authentication & Authorization
- /users/* ‚Üí User Management
- /family/* ‚Üí Family Management
- /animal/* ‚Üí Animal Configuration
- /conversations/* ‚Üí Chat & Conversations

## Frontend Routes
- /admin ‚Üí System Administration
- /admin/animals ‚Üí Animal Configuration
- /admin/families ‚Üí Family Management
- /chat ‚Üí Conversations

## DynamoDB Tables
- quest-dev-family ‚Üí Family Management
- quest-dev-animal-config ‚Üí Animal Configuration
- quest-dev-conversations ‚Üí Chat & Conversations

## Feature Map (Business Capabilities)
1. Authentication & Authorization (Cross-cutting)
2. User Management (Admin)
3. Family Management (Zookeeper/Admin + Parents)
4. Animal Configuration (Zookeeper/Admin)
5. Conversations & Chat (Students + Parents)
6. Knowledge Base Management (Zookeeper/Admin)
7. Analytics & Reporting (Admin)
```

**Common Issues**:
- **Over-granular features**: Don't create separate features for CRUD operations
- **Missing business context**: Always explain WHY the feature exists
- **Role confusion**: Clearly document which roles can access each feature

### Phase 3: Component-Level Documentation

**Best Practices**:
1. **Follow the code** - Document actual implementation, not desired implementation
2. **Include component relationships** - Parent-child hierarchy, sibling dependencies
3. **Document data flow** - How data moves from UI ‚Üí API ‚Üí DynamoDB

**Component Documentation Pattern**:
```markdown
# AnimalConfigDialog Component

## Purpose
Allows zookeepers and admins to configure chatbot personalities for zoo animals,
including system prompts, conversation settings, and behavioral guardrails.

## Location
- File: `frontend/src/components/AnimalConfigDialog.tsx`
- Route: `/admin/animals` (opens as modal dialog)
- Access: Admin, Zookeeper roles only

## Component Structure
- Parent: `AnimalManagementPage`
- Children:
  - `BasicInfoTab` - Animal name, species, personality
  - `SystemPromptTab` - System prompt text editor
  - `SettingsTab` - Voice, AI model, temperature sliders
  - `KnowledgeBaseTab` - Associated knowledge items
  - `GuardrailsTab` - Active safety guardrails

## State Management
- Props:
  - `animalId: string` - ID of animal being edited
  - `open: boolean` - Dialog visibility
  - `onClose: () => void` - Close handler
- State:
  - `animalConfig: AnimalConfig` - Current configuration
  - `isDirty: boolean` - Unsaved changes flag
  - `validationErrors: Record<string, string>` - Validation messages

## API Integration
- **GET /animal/{id}**: Load existing configuration (on dialog open)
- **PATCH /animal_config**: Save configuration changes
- **GET /animals/voices**: Fetch available voice options

Request Flow:
1. Dialog opens ‚Üí GET /animal/{id}
2. User edits fields ‚Üí Local state update
3. User clicks Save ‚Üí PATCH /animal_config
4. Success ‚Üí DynamoDB update confirmed
5. Failure ‚Üí Display error message, stay in dialog

## Fields
See detailed field documentation:
- [Animal Name](fields/animal-name.md) - Text input, required, 3-50 chars
- [System Prompt](fields/system-prompt.md) - Textarea, required, 10-2000 chars
- [Temperature](fields/temperature.md) - Slider, 0.0-1.0, default 0.7
- [Voice](fields/voice.md) - Select, enum from API
- [AI Model](fields/ai-model.md) - Select, enum values

## Actions
- **Save Button**: Validates all fields, calls PATCH /animal_config, closes on success
- **Cancel Button**: Discards changes, closes dialog (prompts if isDirty)
- **Auto-Generate System Prompt**: Calls internal function to generate prompt from personality
- **Reset to Defaults**: Restores default values for current tab

## Validation
Frontend validation before API call:
- All required fields present
- Text lengths within constraints
- Numbers within min/max ranges
- Enums match allowed values

## Error Handling
- **400 Bad Request**: Display field-specific errors from response
- **401 Unauthorized**: Redirect to login
- **404 Not Found**: Animal ID invalid, show error message
- **500 Server Error**: Display generic error, log details
- **Network Error**: Display "Service unavailable" message
```

**Common Issues**:
- **Missing error scenarios**: Document all error conditions, not just happy path
- **Incomplete field list**: Ensure all input fields are documented
- **Vague validation rules**: Be specific about constraints

### Phase 4: Field-Level Specifications

**Best Practices**:
1. **Compare frontend/backend validation** - Document gaps and conflicts
2. **Provide realistic examples** - Show actual valid/invalid values
3. **Document auto-generation** - If field can be auto-filled, explain the logic
4. **Include edge cases** - Comprehensive list for testing agents

**Field Documentation Pattern - System Prompt Example**:
```markdown
# System Prompt Field

## Overview
- **Component**: AnimalConfigDialog ‚Üí SystemPromptTab
- **Feature**: Animal Configuration
- **Type**: textarea (multi-line text input)
- **Required**: Yes

## Purpose
This field contains the English language system prompt that is provided alongside
a chat message from a user. It defines the chatbot's personality, knowledge constraints,
and behavioral guidelines.

The system prompt should:
- Describe the animal's personality traits
- Include active guardrails (safety, age-appropriateness)
- Provide conversation guidelines
- Can be auto-generated from animal personality, then edited by zookeeper

## Technical Description
The system prompt is sent to the LLM (Claude/GPT) as the first message in every
conversation, establishing the chatbot's character and constraints. It's stored in
DynamoDB and retrieved on every chat session initialization.

## Validation Rules

### Frontend Validation
- **Type**: string
- **Required**: Yes (cannot be empty)
- **minLength**: 10 characters
- **maxLength**: 2000 characters
- **pattern**: Alphanumeric + basic punctuation (.,!?- and spaces)
- **Custom validation**: Must contain at least one complete sentence

### Backend Validation (OpenAPI)
- **Field path**: `AnimalConfig.systemPrompt`
- **Type**: string
- **Required**: Yes
- **minLength**: 10
- **maxLength**: 2000
- **pattern**: `^[a-zA-Z0-9\s,.!?-]+$`

### Validation Gaps
‚úÖ Frontend and backend validation are aligned

## Valid Values

### Examples of Valid Input
- Minimum length (10 chars): `I am Leo!`
- Typical value: `I am Leo the lion, king of the savanna. I love teaching kids about wildlife and sharing fun facts about my pride. I'm friendly, curious, and always ready for an adventure!`
- Maximum length (2000 chars): {Paragraph with exactly 2000 characters}

### Examples of Invalid Input
- Empty string: Expected error: "System prompt is required"
- Too short (9 chars): `I am Leo` ‚Üí Error: "System prompt must be at least 10 characters"
- Too long (2001 chars): ‚Üí Error: "System prompt cannot exceed 2000 characters"
- Special chars: `I am Leo @#$%` ‚Üí Error: "System prompt contains invalid characters"
- HTML tags: `I am <b>Leo</b>` ‚Üí Error: "System prompt contains invalid characters"

## Edge Cases for Testing

### Length Boundaries
- Empty string: REJECT - "System prompt is required"
- 9 characters: REJECT - "Must be at least 10 characters"
- 10 characters: ACCEPT - Valid minimum
- 2000 characters: ACCEPT - Valid maximum
- 2001 characters: REJECT - "Cannot exceed 2000 characters"

### Unicode and International
- Chinese characters: `ÊàëÊòØÁãÆÂ≠êÈáåÂ••` - REJECT (pattern doesn't allow)
- Arabic: `ÿ£ŸÜÿß ÿßŸÑÿ£ÿ≥ÿØ ŸÑŸäŸà` - REJECT (pattern doesn't allow)
- Emojis: `I am Leo ü¶Å` - REJECT (pattern doesn't allow)
- Right-to-left text: REJECT (pattern doesn't allow)

**User Clarification Needed**: Should we allow Unicode/emoji in system prompts?
- Current: Restricted to ASCII alphanumeric + basic punctuation
- Impact: Cannot use emojis or non-English characters in prompts

### Security
- HTML tags: `I am <script>alert(1)</script> Leo` - REJECT (pattern)
- SQL injection: `Leo'; DROP TABLE--` - REJECT (pattern)
- Script tags: `<img src=x onerror=alert(1)>` - REJECT (pattern)

### Whitespace
- Leading spaces: `   I am Leo` - ACCEPT (trimmed before save)
- Trailing spaces: `I am Leo   ` - ACCEPT (trimmed before save)
- Only spaces: `          ` - REJECT (fails required + minLength)
- Newlines: `I am Leo\nThe Lion` - REJECT (pattern doesn't allow \n)

**User Clarification Needed**: Should newlines be allowed for multi-paragraph prompts?
- Current: Pattern rejects newlines
- Use case: Long system prompts may benefit from paragraphs

### Large Content
- Lorem ipsum paragraph (500 chars): ACCEPT if within 2000 limit
- Very large block (2500 chars): REJECT - "Cannot exceed 2000 characters"

## Data Persistence
- **DynamoDB Field**: `systemPrompt`
- **Table**: `quest-dev-animal-config`
- **Data Type**: String (S)
- **Persistence Behavior**: Updated via PATCH /animal_config, stored immediately

## Related Fields
- **Animal Name**: Used in auto-generation ("I am {AnimalName}")
- **Personality**: Used in auto-generation to set tone
- **Active Guardrails**: Appended to system prompt automatically
- **Temperature**: Affects how strictly prompt is followed (higher temp = more creative deviation)

## User Guidance
Help text shown below field:
"Define how this animal chatbot responds to students. Include personality traits,
conversation style, and educational goals. You can auto-generate a prompt from the
animal's personality and guardrails, then customize as needed."

## Default Value
None - must be provided by user or auto-generated

## Auto-Generation
System prompt can be auto-generated by clicking "Auto-Generate" button.

**Generation Logic**:
1. Start with template: "I am {AnimalName}, a {Species}. "
2. Add personality traits from Personality field
3. Append active guardrails (age-appropriate language, safety guidelines)
4. Add closing: "I love teaching kids about {Species} and answering questions!"

**Generated Example** (for Leo the Lion with "Friendly, Curious" personality):
```
I am Leo, a lion. I'm friendly and curious, and I love meeting new friends!
I use age-appropriate language and always keep conversations safe and educational.
I love teaching kids about lions and answering questions!
```

After generation, zookeeper can edit the prompt before saving.

## Change History
- 2025-09-15: Field added in initial Animal Configuration implementation
- 2025-09-20: Auto-generation feature added
- 2025-10-01: maxLength reduced from 5000 to 2000 for LLM token optimization
```

**Common Issues**:
- **Vague validation**: Always specify exact constraints (don't say "reasonable length")
- **Missing edge cases**: Use the 25+ edge case categories from testing agent
- **No user guidance**: Include help text users actually see
- **Ignoring auto-generation**: Document any auto-fill or default value logic

### Phase 5: Question Gathering and User Clarification

**Best Practices**:
1. **Ask during documentation** - Don't wait until end to identify gaps
2. **Provide context** - Show where the question arose (file, line, OpenAPI path)
3. **Suggest options** - Give user choices when possible
4. **Prioritize correctly** - Critical questions block documentation completion
5. **Document assumptions** - If user doesn't answer, state what you're assuming

**Question Gathering Pattern**:
```markdown
# Documentation Questions - Animal Configuration

## Critical Questions (Blocking Documentation)

### Question 1: Business Logic - System Prompt Auto-Generation
**Context**: AnimalConfigDialog.tsx:245 - autoGenerateSystemPrompt() function

**Question**: What is the exact algorithm for auto-generating system prompts from
animal personality traits and guardrails?

**Options**:
- Option A: Use template string substitution only
- Option B: Call LLM API to generate creative prompt
- Option C: Combine template with personality keywords from predefined list

**Impact**: Field-level documentation for system-prompt.md, test scenarios for
auto-generation feature

**Priority**: Critical

**Current Assumption**: Using Option A (template substitution) based on code analysis,
but implementation is incomplete and may change.

---

### Question 2: Validation Rules - Unicode Support in System Prompts
**Context**: openapi_spec.yaml:1234 - AnimalConfig.systemPrompt pattern constraint

**Question**: Should system prompts allow Unicode characters (emoji, non-English)?

**Current State**:
- OpenAPI pattern: `^[a-zA-Z0-9\s,.!?-]+$` (ASCII only)
- Frontend validation: Matches OpenAPI pattern
- Potential use case: Emoji in prompts for student engagement

**Options**:
- Option A: Keep ASCII-only for consistency and security
- Option B: Allow Unicode for better expressiveness
- Option C: Allow emoji only (no full Unicode)

**Impact**: Field-level validation rules, test edge cases, security considerations

**Priority**: Critical

**Current Assumption**: ASCII-only per OpenAPI spec, but this may limit chatbot
expressiveness and international usage.

## High Priority Questions (Affects Test Scenarios)

### Question 3: Edge Cases - Newlines in System Prompts
**Context**: Field documentation for system-prompt.md

**Question**: Should multi-line system prompts with newlines be allowed?

**Current State**:
- OpenAPI pattern rejects newlines (no \n in pattern)
- UI uses textarea (suggests multi-line is intended)
- Inconsistency between UI widget type and validation

**Options**:
- Option A: Allow newlines for paragraph structure
- Option B: Reject newlines, use spaces only
- Option C: Allow newlines but normalize to spaces before persistence

**Impact**: Test edge cases, UI behavior, user experience

**Priority**: High

**Current Assumption**: Newlines rejected per OpenAPI pattern, but UI should
probably use text input (not textarea) for consistency.

---

### Question 4: Data Persistence - Temperature Field Precision
**Context**: AnimalConfigDialog temperature slider, DynamoDB schema

**Question**: What precision should temperature values have in DynamoDB?

**Current State**:
- Frontend slider: Steps of 0.1 (values like 0.7, 0.8, 0.9)
- OpenAPI type: number (no precision specified)
- DynamoDB type: Number (can store arbitrary precision)

**Options**:
- Option A: Store 1 decimal place (0.7) for simplicity
- Option B: Store 2 decimal places (0.70) for consistency
- Option C: Store full precision (0.7000000000000001) as JavaScript provides

**Impact**: Data persistence documentation, test assertions, value comparison logic

**Priority**: High

**Current Assumption**: Using 1 decimal place (0.7) based on slider step size.

## Medium Priority Questions (Clarifications)

### Question 5: User Experience - Save Button Behavior
**Context**: AnimalConfigDialog save button behavior

**Question**: Should the save button close the dialog on success, or stay open?

**Current State**:
- Code shows dialog closes on successful save
- No confirmation message shown
- User might expect to see success message before dialog closes

**Options**:
- Option A: Close immediately (current behavior)
- Option B: Show success message, wait 1 second, then close
- Option C: Show success message, user must click "Done" to close

**Impact**: Component documentation, user experience description, test verification

**Priority**: Medium

**Current Assumption**: Using Option A (close immediately) per current implementation.

## Low Priority Questions (Nice to Have)

### Question 6: Future Enhancement - Prompt Templates
**Context**: Auto-generation feature for system prompts

**Question**: Are there plans for pre-defined prompt templates users can choose from?

**Impact**: Future feature documentation, architecture planning

**Priority**: Low

**Current Assumption**: No template library planned at this time.
```

**User Answer Processing**:
When user provides answers, update documentation immediately:

```markdown
<!-- Before User Answer -->
**Current Assumption**: ASCII-only per OpenAPI spec, but this may limit chatbot
expressiveness and international usage.

<!-- After User Answer -->
**User Confirmed (2025-10-12)**: ASCII-only is correct. System prompts are English-only
to maintain consistency with LLM training data and ensure predictable behavior.
Emoji support may be added in future release after testing LLM handling.
```

**Common Issues**:
- **Too many questions**: Limit to <10 questions per feature to avoid overwhelming user
- **Vague questions**: Always provide context and specific options
- **Wrong priority**: Critical = blocks docs, High = affects tests, Medium = improves clarity
- **Not recording answers**: Always update sources/user-clarifications.md with answers

### Phase 6: Test Documentation and Maintenance

**Best Practices**:
1. **Generate test scenarios from field docs** - Edge cases already documented
2. **Link test scenarios to components** - Clear traceability
3. **Update test docs when code changes** - Keep in sync with implementation
4. **Provide DynamoDB verification steps** - Show how to confirm persistence

**Test Scenario Pattern**:
```markdown
# Test Scenarios: Animal Configuration

## Happy Path Scenarios

### Scenario 1: Create New Animal Configuration with Auto-Generated System Prompt
**Preconditions**:
- Logged in as admin or zookeeper
- At least one animal exists in system

**Steps**:
1. Navigate to `/admin/animals`
2. Click "Configure" button for specific animal
3. AnimalConfigDialog opens
4. Click "Basic Info" tab
5. Enter Animal Name: "Leo"
6. Enter Species: "Lion"
7. Enter Personality: "Friendly, curious, loves teaching"
8. Click "System Prompt" tab
9. Click "Auto-Generate" button
10. System generates prompt: "I am Leo, a lion. I'm friendly, curious, and love teaching..."
11. (Optional) Edit generated prompt
12. Click "Save" button

**Expected Results**:
- Auto-generated prompt appears in textarea (Step 10)
- Save button enables (Step 11)
- Dialog closes on save (Step 12)
- Success message flashes briefly
- API call: PATCH /animal_config with systemPrompt field
- DynamoDB record updated in quest-dev-animal-config table

**DynamoDB Verification**:
```bash
aws dynamodb get-item \
  --table-name quest-dev-animal-config \
  --key '{"animalId": {"S": "{animal-id}"}}' \
  --query 'Item.systemPrompt.S'
```
Expected: System prompt matches value from Step 10/11

---

### Scenario 2: Edit Existing Configuration - Temperature Slider
**Preconditions**:
- Animal configuration already exists
- Temperature currently set to 0.7

**Steps**:
1. Open AnimalConfigDialog for animal
2. Click "Settings" tab
3. Drag temperature slider from 0.7 to 0.9
4. Verify preview shows "0.9"
5. Click "Save"

**Expected Results**:
- Slider updates smoothly (Step 3)
- Preview updates in real-time (Step 4)
- API call: PATCH /animal_config with temperature=0.9
- DynamoDB field updated to 0.9

**DynamoDB Verification**:
```bash
aws dynamodb get-item \
  --table-name quest-dev-animal-config \
  --key '{"animalId": {"S": "{animal-id}"}}' \
  --query 'Item.temperature.N'
```
Expected: "0.9"

## Failure Scenarios

### Scenario 1: System Prompt Too Short (Below minLength)
**Preconditions**: Animal Config Dialog open

**Steps**:
1. Navigate to "System Prompt" tab
2. Enter "I am Leo" (9 characters, below 10 minimum)
3. Click "Save"

**Expected Results**:
- Save button may be disabled (if validation is real-time)
- OR: Error message appears: "System prompt must be at least 10 characters"
- Dialog stays open
- No API call made
- DynamoDB not updated

---

### Scenario 2: System Prompt Contains Invalid Characters
**Preconditions**: Animal Config Dialog open

**Steps**:
1. Navigate to "System Prompt" tab
2. Enter "I am Leo ü¶Å" (contains emoji)
3. Click "Save"

**Expected Results**:
- Error message: "System prompt contains invalid characters"
- Field highlighted with error styling
- Dialog stays open
- No API call made

---

### Scenario 3: Network Error During Save
**Preconditions**:
- Animal Config Dialog open with valid data
- Simulate network error (disconnect network OR use browser dev tools to block request)

**Steps**:
1. Fill in valid system prompt
2. Click "Save"
3. Network request fails

**Expected Results**:
- Loading indicator shows briefly
- Error message appears: "Service temporarily unavailable. Please try again."
- Dialog stays open
- User can retry save
- DynamoDB not updated

## Edge Cases

### Edge Case 1: Maximum Length System Prompt (2000 characters)
**Input**: Lorem ipsum text exactly 2000 characters long
**Expected**: ACCEPT - Saved successfully to DynamoDB
**Actual**: {To be verified by testing agent}
**Priority**: High

### Edge Case 2: Maximum Length + 1 (2001 characters)
**Input**: Lorem ipsum text exactly 2001 characters long
**Expected**: REJECT - Error: "System prompt cannot exceed 2000 characters"
**Actual**: {To be verified by testing agent}
**Priority**: High

### Edge Case 3: Leading/Trailing Whitespace
**Input**: "   I am Leo the lion   " (leading and trailing spaces)
**Expected**: ACCEPT - Spaces trimmed, saved as "I am Leo the lion"
**Actual**: {To be verified by testing agent}
**Priority**: Medium

### Edge Case 4: Only Whitespace
**Input**: "          " (10 spaces)
**Expected**: REJECT - Fails required validation + minLength after trimming
**Actual**: {To be verified by testing agent}
**Priority**: High

### Edge Case 5: Temperature Slider Out of Range (Below Minimum)
**Input**: Manually set slider value to -0.1 (via browser console)
**Expected**: REJECT - Frontend validation prevents negative values
**Actual**: {To be verified by testing agent}
**Priority**: Medium

### Edge Case 6: Temperature Slider Out of Range (Above Maximum)
**Input**: Manually set slider value to 1.5 (via browser console)
**Expected**: REJECT - Frontend validation clamps to 1.0
**Actual**: {To be verified by testing agent}
**Priority**: Medium

### Edge Case 7: Concurrent Edits (Two Zookeepers Edit Same Animal)
**Setup**:
- Zookeeper A opens Animal Config Dialog for "Leo"
- Zookeeper B opens Animal Config Dialog for "Leo"
- Zookeeper A changes system prompt to "Prompt A" and saves
- Zookeeper B changes system prompt to "Prompt B" and saves

**Expected**: Last write wins (Prompt B), OR conflict detection with error message
**Actual**: {To be verified by testing agent}
**Priority**: Low (rare scenario)
```

**Common Issues**:
- **Missing DynamoDB verification** - Always show how to verify persistence
- **No failure scenarios**: Document error cases, not just happy path
- **Vague expected results**: Be specific about error messages and behavior

## Integration with Other Agents

### Frontend Testing Agent Integration

**How Testing Agent Uses Feature Docs**:

1. **Phase 2 - Component Discovery**:
   - Read `documentation-index.json` to get complete component list
   - No need to manually discover components - already documented
   - Map roles to components using feature docs

2. **Phase 3 - OpenAPI Validation**:
   - Field docs already contain OpenAPI constraints
   - Compare field docs to OpenAPI spec to verify alignment
   - Report any documentation-spec mismatches as bugs

3. **Phase 4 - Text Input Edge Case Testing**:
   - Field docs contain comprehensive edge case lists
   - Use edge cases directly from field documentation
   - Report actual behavior back to documentation for "Actual" field

4. **Phase 5 - Control Testing**:
   - Component docs list all controls (sliders, selects, checkboxes)
   - Field docs specify ranges and options
   - Test docs provide expected behavior

5. **Phase 6 - Test Reporting**:
   - Use test scenario docs as checklist
   - Report which scenarios passed/failed
   - Link failures to specific field docs

**Updated Testing Agent Workflow**:
```python
Task(
    subagent_type="general-purpose",
    description="Frontend comprehensive testing WITH feature docs",
    prompt="""You are a Senior Frontend QA Engineer.

BEFORE TESTING:
1. Read claudedocs/features/documentation-index.json to get component inventory
2. Read claudedocs/features/{feature}/frontend/components.md for component details
3. Read claudedocs/features/{feature}/frontend/fields/*.md for field-level specs
4. Read claudedocs/features/{feature}/testing/test-scenarios.md for test checklist

DURING TESTING:
- Use edge cases from field documentation (already comprehensive)
- Follow test scenarios from test-scenarios.md
- Report actual behavior back to documentation

AFTER TESTING:
- Update test-scenarios.md with actual results
- Report documentation bugs if docs don't match implementation
"""
)
```

### Frontend Developer Agent Integration

**How Developer Agent Uses Feature Docs**:

1. **Understanding Requirements**:
   - Read `{feature}/README.md` for business value and user capabilities
   - Read `{feature}/user-journeys.md` for expected user workflows

2. **Implementing Components**:
   - Read `{feature}/frontend/components.md` for component specifications
   - Read `{feature}/frontend/fields/*.md` for field validation rules
   - Read `{feature}/integration/frontend-backend-flow.md` for API integration

3. **Validation Implementation**:
   - Use validation rules from field docs
   - Ensure frontend validation matches OpenAPI spec
   - Report documentation bugs if requirements are unclear

**Updated Developer Agent Workflow**:
```python
Task(
    subagent_type="frontend-architect",
    description="Implement feature WITH feature docs",
    prompt="""You are a Senior Frontend Developer.

BEFORE IMPLEMENTING:
1. Read claudedocs/features/{feature}/README.md for business requirements
2. Read claudedocs/features/{feature}/frontend/components.md for component specs
3. Read claudedocs/features/{feature}/frontend/fields/*.md for validation rules
4. Read claudedocs/features/{feature}/integration/frontend-backend-flow.md for API integration

IMPLEMENTATION CHECKLIST:
- [ ] Component structure matches component.md specification
- [ ] All fields have validation per field docs
- [ ] Frontend validation matches OpenAPI constraints
- [ ] Error handling covers all failure scenarios from test docs
- [ ] Data persistence verified per integration docs

AFTER IMPLEMENTING:
- Update component docs if implementation differs from spec (with user approval)
- Report documentation gaps or ambiguities
"""
)
```

### Backend Developer Agent Integration

**How Backend Agent Uses Feature Docs**:

1. **API Implementation**:
   - Read `{feature}/backend/api-endpoints.md` for endpoint requirements
   - Read `{feature}/backend/dynamodb-schema.md` for data persistence
   - Read field docs for validation constraint details

2. **Validation Implementation**:
   - Ensure OpenAPI spec matches field documentation
   - Implement backend validation per OpenAPI constraints
   - Report documentation bugs if OpenAPI spec is incomplete

## Documentation Maintenance

### When to Update Documentation

**Triggers for Documentation Updates**:
1. **OpenAPI spec changes** - Regenerate affected field docs
2. **Component file changes** - Update component documentation
3. **New feature added** - Create full feature documentation
4. **Validation rules changed** - Update field docs and test scenarios
5. **Bug fixes** - Update edge case actual behavior
6. **User clarifications** - Incorporate answers into docs

### Update Detection Pattern

**Automated Change Detection**:
```bash
# Check for OpenAPI changes
git diff HEAD~1 backend/api/openapi_spec.yaml

# Check for component changes
git diff HEAD~1 frontend/src/components/

# Identify affected documentation
# If AnimalConfigDialog.tsx changed:
#   - Update: claudedocs/features/animal-configuration/frontend/components.md
#   - Review: All field docs under animal-configuration/frontend/fields/
#   - Verify: Test scenarios still valid
```

**Update Workflow**:
1. Detect source file changes (git diff)
2. Identify affected documentation (documentation-index.json)
3. Run `/document-features --update {feature}`
4. Review generated changes
5. Update documentation-index.json with new timestamp
6. Record update in sources/update-history.md

### Version Control for Documentation

**Best Practices**:
- Commit documentation changes with code changes
- Use descriptive commit messages: "docs: update animal-config field validation after OpenAPI changes"
- Tag documentation versions: "docs-v1.0", "docs-v1.1"
- Maintain update-history.md with change log

## Troubleshooting

### Common Issues and Solutions

**Issue**: Documentation conflicts with implementation
**Solution**: Ask user for clarification in Phase 5, document answer

**Issue**: OpenAPI spec missing validation constraints
**Solution**: Document as Critical bug, propose constraints based on frontend code

**Issue**: Too many features to document at once
**Solution**: Use `--feature {name}` flag to document incrementally

**Issue**: Field documentation taking too long
**Solution**: Use `--component` flag to document single component first

**Issue**: Test scenarios outdated after code changes
**Solution**: Run `/document-features --update --test-docs {feature}`

**Issue**: User clarifications contradict existing code
**Solution**: Document conflict, recommend code changes to match requirements

## Quality Checklist

Before considering documentation complete, verify:

- [ ] Every feature has README.md with business value
- [ ] Every UI component has component documentation
- [ ] Every input field has field-level documentation with:
  - [ ] Purpose (user-facing description)
  - [ ] Validation rules (frontend and backend)
  - [ ] Valid/invalid examples
  - [ ] Edge cases (25+ categories)
  - [ ] Data persistence details
- [ ] Every API endpoint documented with:
  - [ ] Request parameters and body
  - [ ] Response format and errors
  - [ ] Implementation details
  - [ ] DynamoDB operations
- [ ] Test documentation includes:
  - [ ] Happy path scenarios
  - [ ] Failure scenarios
  - [ ] Edge cases with expected behavior
  - [ ] DynamoDB verification steps
- [ ] documentation-index.json is up-to-date
- [ ] All user clarifications recorded in sources/user-clarifications.md
- [ ] Update history maintained in sources/update-history.md

## Success Metrics

- **Coverage**: 100% of UI components documented within 1 week of implementation
- **Accuracy**: <5% documentation-code mismatches reported by developers
- **Usability**: Testing agent successfully generates test cases from field docs
- **Freshness**: Documentation updated within 24 hours of code changes
- **Completeness**: All field docs have ‚â•20 edge cases documented
- **Collaboration**: <3 clarification questions per feature from testing agent

## Command Quick Reference

```bash
# Document entire feature
/document-features animal-configuration

# Update existing documentation after code changes
/document-features --update family-management

# Document specific component
/document-features --component AnimalConfigDialog

# Document all fields across all features
/document-features --all-fields

# Generate test documentation only
/document-features --test-docs animal-configuration

# Verify documentation matches current code
/document-features --verify

# Update JSON index only
/document-features --json-only
```
